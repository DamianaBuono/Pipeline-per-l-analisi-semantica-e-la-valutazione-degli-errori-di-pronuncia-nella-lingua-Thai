{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"fsctfDizTQIa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759222313557,"user_tz":-120,"elapsed":119536,"user":{"displayName":"Damiana Buono","userId":"07683593436020307333"}},"outputId":"c21da5c4-c336-464b-fd40-9b32463220e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"iuKLBQ5XpcAR"},"source":["Trascrizione dell'audio Madrelingua Thai tramite il Modello **Wav2vec2.0 Thai**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"c2LUNxLrUgxI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759160632795,"user_tz":-120,"elapsed":35254,"user":{"displayName":"Damiana Buono","userId":"07683593436020307333"}},"outputId":"80e4b031-8d5e-4573-cd78-38fc6cb6ccf3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.2)\n","Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n","Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (2.8.8)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n","Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n","Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n","Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.1)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"]}],"source":["!pip install torch torchaudio transformers librosa soundfile\n","!apt-get install -y ffmpeg"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"VX3m7ywijTRF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759137370453,"user_tz":-120,"elapsed":2466,"user":{"displayName":"Damiana Buono","userId":"07683593436020307333"}},"outputId":"13c5ba02-be8c-438c-d8d4-9a2be8565249"},"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cpu\n"]}],"source":["# Use a pipeline as a high-level helper\n","from transformers import pipeline\n","\n","pipe = pipeline(\"automatic-speech-recognition\", model=\"airesearch/wav2vec2-large-xlsr-53-th\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-k-ItdTulaB4"},"outputs":[],"source":["# Load model directly\n","from transformers import AutoProcessor, AutoModelForCTC\n","\n","processor = AutoProcessor.from_pretrained(\"airesearch/wav2vec2-large-xlsr-53-th\")\n","model = AutoModelForCTC.from_pretrained(\"airesearch/wav2vec2-large-xlsr-53-th\")"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"puHm9SF-pDt-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759160653806,"user_tz":-120,"elapsed":21008,"user":{"displayName":"Damiana Buono","userId":"07683593436020307333"}},"outputId":"7d041569-e20e-4600-ab30-cd5adeb0eff8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.2)\n","Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchaudio) (2.6.0+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2.8.8)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchaudio) (1.3.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchaudio) (3.0.2)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"]}],"source":["!pip install torchaudio transformers\n","!apt-get install -y ffmpeg"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"WmEtbD_FpIBV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759137404231,"user_tz":-120,"elapsed":9954,"user":{"displayName":"Damiana Buono","userId":"07683593436020307333"}},"outputId":"8d5ed213-b303-4b40-8366-8aba648eab2d"},"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cpu\n"]},{"output_type":"stream","name":"stdout","text":["Trascrizione (corretta): และ เพื่อให้ อัตราส่วน โอกาส ที่จะ มี ข้อมูล เป็น ลอจิก หนึ่ง  หรือ ลอจิก ศูนย์ เท่า เท่ากัน\n"]}],"source":["import torchaudio\n","import torchaudio.transforms as T\n","from transformers import pipeline\n","import numpy as np\n","\n","# Inizializza la pipeline ASR Thai\n","pipe = pipeline(\"automatic-speech-recognition\", model=\"airesearch/wav2vec2-large-xlsr-53-th\")\n","\n","def prepara_audio(percorso_audio):\n","    # Carica e prepara l'audio\n","    waveform, sample_rate = torchaudio.load(percorso_audio)\n","\n","    # Converte in mono se necessario\n","    if waveform.shape[0] > 1:\n","        waveform = waveform.mean(dim=0, keepdim=True)\n","\n","    # Resample a 16 kHz\n","    if sample_rate != 16000:\n","        resampler = T.Resample(orig_freq=sample_rate, new_freq=16000)\n","        waveform = resampler(waveform)\n","\n","    return waveform.squeeze().numpy()\n","\n","# Percorsi degli audio\n","audio_corretto_path = \"/content/drive/MyDrive/TesiMaggistrale/Lotus_dataset/PD/C/Clean/Wav/CCF001_Pa001/CCF001_Pa001_008.wav\"\n","#audio_corrotto_path =\"/content/drive/MyDrive/TesiMaggistrale/audiErrati/Corpus_InjectionOfError/C/Clean/Wav/CCF001_Pa001/CCF001_Pa001_008_corrupted.wav\"\n","# Prepara gli audio\n","audio_corretto = prepara_audio(audio_corretto_path)\n","#audio_corrotto = prepara_audio(audio_corrotto_path)\n","# Trascrizione\n","trascrizione_corretto = pipe(audio_corretto)[\"text\"]\n","#trascrizione_corrotto = pipe(audio_corrotto)[\"text\"]\n","# Stampa dei risultati\n","print(\"Trascrizione (corretta):\", trascrizione_corretto)\n","#print(\"Trascrizione (CORROTTA):\", trascrizione_corrotto)"]},{"cell_type":"markdown","metadata":{"id":"XosgST9zvMhB"},"source":["**Iniezione di errori di pronuncia su fonemi e toni Thai**"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"Ahy1MGnJDn1W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759160664995,"user_tz":-120,"elapsed":11165,"user":{"displayName":"Damiana Buono","userId":"07683593436020307333"}},"outputId":"9f1011bd-772c-4dd9-dcf5-b3c15c798907"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pythainlp in /usr/local/lib/python3.11/dist-packages (5.1.2)\n","Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from pythainlp) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->pythainlp) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->pythainlp) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->pythainlp) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->pythainlp) (2025.7.14)\n"]}],"source":["!pip install pythainlp"]},{"cell_type":"code","source":["import random\n","import nltk\n","from pythainlp.corpus.common import thai_words\n","# synsets: interfaccia al WordNet Thai, usata per ottenere insiemi di sinonimi (synset),  significati e relazioni semantiche tra le parole\n","from pythainlp.corpus.wordnet import synsets\n","\n","# Assicura la presenza di WordNet\n","try:\n","    nltk.data.find('corpora/omw-1.4')\n","except LookupError:\n","    nltk.download('omw-1.4')\n","\n","# Dizionario confusione esteso\n","pronunciation_confusions = {\n","    'light': {\n","        'consonants': {\n","            'ด': ['ต'], 'ต': ['ด'],\n","            'ร': ['ล'], 'ล': ['ร'],\n","            'บ': ['ป'], 'ป': ['บ'],\n","            'น': ['ม'], 'ม': ['น'],  # aggiunte\n","        },\n","        'vowels': {\n","            'า': ['ั'], 'ั': ['า'],\n","            'เ': ['แ'], 'แ': ['เ'],\n","            'ะ': ['า'], 'า': ['ะ'],  # aggiunte\n","        },\n","    },\n","    'heavy': {\n","        'consonants': {\n","            'บ': ['พ'], 'พ': ['บ'],\n","            'ช': ['ซ'], 'ซ': ['ช'],\n","            'ง': ['น'], 'น': ['ง'],\n","            'ก': ['ข', 'ค'], 'ข': ['ก'], 'ค': ['ก'],\n","            'ญ': ['ย'], 'ย': ['ญ'],  # aggiunte\n","        },\n","        'vowels': {\n","            'ิ': ['ี'], 'ี': ['ิ'],\n","            'ุ': ['ู'], 'ู': ['ุ'],\n","            'อ': ['โ'], 'โ': ['อ'],\n","        },\n","    },\n","    'tones': ['่', '้', '๊', '๋']\n","}\n","\n","thai_vocab = set(thai_words())\n","tone_possible_chars = set(\"กขคฆงจชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลวสหฬอฮ\")\n","\n","\n","def is_valid_lexical(word):\n","    return word in thai_vocab\n","\n","\n","def is_valid_semantic(word):\n","    return len(synsets(word)) > 0\n","\n","\n","def generate_pronunciation_variants(word, severity='light', max_steps=3):\n","    \"\"\"\n","    Genera varianti di pronuncia di una parola simulando errori tipici.\n","    Garantisce che ogni rimozione di vocale o tono sia bilanciata da una sostituzione plausibile.\n","    \"\"\"\n","    consonants = pronunciation_confusions[severity]['consonants']\n","    vowels = pronunciation_confusions[severity]['vowels']\n","    tones = pronunciation_confusions['tones']\n","\n","    variants = set()\n","\n","    def recursive_modify(current_word, steps_left, changes):\n","        if steps_left == 0:\n","            return\n","\n","        for i, char in enumerate(current_word):\n","            new_variants = []\n","\n","            # Sostituzione consonante\n","            if char in consonants:\n","                for rep in consonants[char]:\n","                    mod_word = current_word[:i] + rep + current_word[i+1:]\n","                    new_variants.append((mod_word, changes + [(char, rep, 'suono_consonante')]))\n","\n","            # Sostituzione vocale\n","            if char in vowels:\n","                for rep in vowels[char]:\n","                    mod_word = current_word[:i] + rep + current_word[i+1:]\n","                    new_variants.append((mod_word, changes + [(char, rep, 'suono_vocale')]))\n","\n","            # Inserimento di tono\n","            if char in tone_possible_chars:\n","                for tone in tones:\n","                    mod_word = current_word[:i+1] + tone + current_word[i+1:]\n","                    new_variants.append((mod_word, changes + [('', tone, 'aggiunta_tono')]))\n","\n","            # Rimozione di tono o vocale → sostituzione alternativa se possibile\n","            if char in tones + list(vowels.keys()):\n","                # Prova a sostituire con un altro carattere simile\n","                if char in vowels:\n","                    alt_chars = [v for v in vowels[char] if v != char]\n","                    for alt in alt_chars:\n","                        mod_word = current_word[:i] + alt + current_word[i+1:]\n","                        new_variants.append((mod_word, changes + [(char, alt, 'sostituzione_vocale')]))\n","                elif char in tones:\n","                    alt_chars = [t for t in tones if t != char]\n","                    for alt in alt_chars:\n","                        mod_word = current_word[:i] + alt + current_word[i+1:]\n","                        new_variants.append((mod_word, changes + [(char, alt, 'sostituzione_tono')]))\n","\n","            for variant, var_changes in new_variants:\n","                if variant not in variants:\n","                    variants.add((variant, tuple(var_changes)))\n","                    recursive_modify(variant, steps_left - 1, var_changes)\n","\n","    recursive_modify(word, max_steps, [])\n","    return list(variants)\n","\n","\n","def inject_pronunciation_error(word, severity='light', max_steps=3):\n","    variants = generate_pronunciation_variants(word, severity=severity, max_steps=max_steps)\n","\n","    # Filtra varianti valide e diverse dall'originale\n","    valid_variants = [(w, list(changes)) for (w, changes) in variants\n","                      if (is_valid_lexical(w) or is_valid_semantic(w)) and w != word]\n","\n","    if valid_variants:\n","        chosen_word, changes = random.choice(valid_variants)\n","        return chosen_word, changes, True\n","\n","    return word, [], False\n","\n","\n","def maybe_inject_pronunciation_multi_scaled(sentence, reference_sentence,\n","                                            base_inject_prob=0.2, severity='light', min_distance=1):\n","    \"\"\"\n","    Simula errori di pronuncia in una frase:\n","    - Più modifiche distribuite nella frase, scalate con la lunghezza\n","    - Una sola modifica per parola\n","    - Riallinea la frase con gli spazi della reference_sentence\n","    - Distanza minima tra parole modificate\n","    \"\"\"\n","    reference_words = reference_sentence.split()\n","    words = sentence.split()\n","    modified_words = []\n","    full_changes = []\n","    modified_flag = False\n","\n","    last_modified_idx = -min_distance - 1\n","\n","    # Calcolo probabilità scalata in base alla lunghezza della frase\n","    length = len(words)\n","    scaled_prob = base_inject_prob + 0.02 * length\n","    scaled_prob = min(scaled_prob, 0.5)  # massimo 50%\n","\n","    for i, word in enumerate(words):\n","        # Evita cluster troppo vicini\n","        if i - last_modified_idx <= min_distance:\n","            modified_words.append(word)\n","            full_changes.append((word, word, [], False))\n","            continue\n","\n","        word_severity = severity\n","        if random.random() < 0.3:\n","            word_severity = 'heavy' if severity == 'light' else 'light'\n","\n","        # Decidi se modificare la parola\n","        if random.random() < scaled_prob:\n","            variants = generate_pronunciation_variants(word, severity=word_severity, max_steps=1)\n","            valid_variants = [(w, list(changes)) for (w, changes) in variants\n","                              if (is_valid_lexical(w) or is_valid_semantic(w)) and w != word]\n","\n","            if valid_variants:\n","                chosen_word, changes = random.choice(valid_variants)\n","                applied = True\n","                modified_flag = True\n","                last_modified_idx = i\n","            else:\n","                chosen_word, changes, applied = word, [], False\n","        else:\n","            chosen_word, changes, applied = word, [], False\n","\n","        modified_words.append(chosen_word)\n","        full_changes.append((word, chosen_word, changes, applied))\n","\n","    # Riallineamento con spazi della reference_sentence\n","    new_sentence = ' '.join(modified_words[:len(reference_words)])\n","    return new_sentence, full_changes, modified_flag\n","\n","# --- Esempio di utilizzo ---\n","sentence_no_spaces = \"ฉัน รัก ภาษาไทย มาก\"\n","reference_sentence = sentence_no_spaces\n","\n","corrupted, error_log, modified = maybe_inject_pronunciation_multi_scaled(\n","    sentence_no_spaces,\n","    reference_sentence,\n","    base_inject_prob=0.2,\n","    severity='light',\n","    min_distance=1\n",")\n","\n","print(\" Originale:\", sentence_no_spaces)\n","print(\" Simulazione errori di pronuncia:\", corrupted)\n","\n","# Stampa log modifiche\n","modifiche_effettive = [entry for entry in error_log if entry[3] is True]\n","if not modifiche_effettive:\n","    print(\" Nessuna modifica effettuata.\")\n","else:\n","    for original, modified_word, changes, is_valid in modifiche_effettive:\n","        print(f\"- '{original}' → '{modified_word}' Modificata\")\n","        for old, new_c, err_type in changes:\n","            if old == '':\n","                print(f\"    + Aggiunto tono: '{new_c}'\")\n","            elif new_c == '':\n","                print(f\"    - Rimosso '{old}' ({err_type})\")\n","            else:\n","                print(f\"    x {err_type.upper()} - '{old}' → '{new_c}'\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uk-o4pMa3gdT","executionInfo":{"status":"ok","timestamp":1759139101497,"user_tz":-120,"elapsed":14387,"user":{"displayName":"Damiana Buono","userId":"07683593436020307333"}},"outputId":"7e88fff8-72ae-44c0-b646-ac5193de1d58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package omw to /root/nltk_data...\n","[nltk_data]   Package omw is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":[" Originale: ฉัน รัก ภาษาไทย มาก\n"," Simulazione errori di pronuncia: ฉัน รัก ภาษาไทย นาก\n","- 'มาก' → 'นาก' Modificata\n","    x SUONO_CONSONANTE - 'ม' → 'น'\n"]}]},{"cell_type":"markdown","metadata":{"id":"N8QJfKUFY6H2"},"source":["***Pipline Completa!***"]},{"cell_type":"code","source":["import os\n","import csv\n","import torchaudio\n","import torchaudio.transforms as T\n","from transformers import pipeline\n","from pythaitts import TTS\n","from pythainlp import word_tokenize\n","\n","# Percorsi\n","AUDIO_DIR = \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOM046_Pa046\"\n","OUTPUT_DIR = \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/Corpus_Injection_error_thai/\"\n","CSV_PATH = os.path.join(OUTPUT_DIR, \"pronunciation_error_dataset.csv\")\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","sr_pipe = pipeline(\"automatic-speech-recognition\", model=\"airesearch/wav2vec2-large-xlsr-53-th\")\n","tts_model = TTS(pretrained=\"khanomtan\", version=\"1.0\", mode=\"best_model\")\n","\n","# Funzione per preparare audio per ASR\n","def prepara_audio(path):\n","    waveform, sr = torchaudio.load(path)\n","    if waveform.shape[0] > 1:\n","        waveform = waveform.mean(dim=0, keepdim=True)\n","    if sr != 16000:\n","        waveform = T.Resample(sr, 16000)(waveform)\n","    return waveform.squeeze().numpy()\n","\n","# Inizializza il CSV con intestazioni se non esiste\n","if not os.path.exists(CSV_PATH):\n","    with open(CSV_PATH, mode=\"w\", encoding=\"utf-8\", newline=\"\") as f:\n","        writer = csv.writer(f)\n","        writer.writerow([\"filename\", \"trascrizione_originale\", \"trascrizione_errata\", \"modificata\", \"dettagli_modifiche\", \"audio_path\"])\n","\n","# Trova file audio\n","audio_files = []\n","for root, _, files in os.walk(AUDIO_DIR):\n","    for file in files:\n","        if file.endswith(\".wav\"):\n","            audio_files.append(os.path.join(root, file))\n","\n","print(f\"Trovati {len(audio_files)} file audio.\")\n","\n","# Loop\n","for audio_path in audio_files:\n","    try:\n","        base_name = os.path.splitext(os.path.basename(audio_path))[0]\n","\n","        # Step 1: ASR\n","        audio_data = prepara_audio(audio_path)\n","        trascrizione = sr_pipe(audio_data)[\"text\"]\n","        frase_no_spazi = trascrizione.replace(\" \", \"\")\n","        reference_sentence = frase_no_spazi\n","\n","        # Step 1.1: Tokenizzazione Thai\n","        tokens = word_tokenize(frase_no_spazi, engine=\"newmm\")\n","        frase_tokenizzata = \" \".join(tokens)\n","        reference_sentence = frase_tokenizzata\n","\n","        # Step 2: Iniezione errori\n","        frase_errata, log_error, modificato = maybe_inject_pronunciation_multi_scaled(\n","            frase_no_spazi,\n","            reference_sentence,\n","            base_inject_prob=0.2,\n","            severity='light',\n","            min_distance=1\n","        )\n","\n","        # Step 3: TTS\n","        audio_out_path = os.path.join(OUTPUT_DIR, f\"{base_name}_corrupted.wav\")\n","        tts_model.tts(\n","            text=frase_errata,\n","            speaker_idx=\"Tsyncone\",\n","            language_idx=\"th-th\",\n","            return_type=\"file\",\n","            filename=audio_out_path\n","        )\n","\n","        # Step 4: Log dettagliato modifiche\n","        if not modificato:\n","            dettagli = \"Nessuna modifica\"\n","        else:\n","            modifiche_effettive = [entry for entry in log_error if entry[3] is True]\n","            dettaglio_lista = []\n","            for original_w, modified_w, changes, _ in modifiche_effettive:\n","                for old, new_c, tipo in changes:\n","                    if old == '':\n","                        dettaglio_lista.append(f\"Aggiunto tono: '{new_c}' in '{modified_w}'\")\n","                    elif new_c == '':\n","                        dettaglio_lista.append(f\"Rimosso '{old}' da '{original_w}'\")\n","                    else:\n","                        dettaglio_lista.append(f\"{tipo.upper()} - '{original_w}': '{old}'→'{new_c}'\")\n","            dettagli = \" | \".join(dettaglio_lista) if dettaglio_lista else \"Nessuna modifica\"\n","\n","        # Step 5: Salva nel CSV\n","        with open(CSV_PATH, mode=\"a\", encoding=\"utf-8\", newline=\"\") as f:\n","            writer = csv.writer(f)\n","            writer.writerow([\n","                base_name,\n","                trascrizione,\n","                frase_errata,\n","                \"SI\" if modificato else \"NO\",\n","                dettagli,\n","                audio_out_path\n","            ])\n","\n","        print(f\"✅ Salvato: {base_name}\")\n","\n","    except Exception as e:\n","        print(f\"❌ Errore su {audio_path}: {str(e)}\")\n","\n","print(\"✅ Creazione database completata.\")\n"],"metadata":{"id":"vOnqSe1nSHKF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7xfOZ6rjoVqK"},"source":["UNIONE DELLE DIVERSE CARTELLE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gj_O5NTDoVLi"},"outputs":[],"source":["import os\n","import pandas as pd\n","\n","cartelle = [\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Clean/Wav\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Clean/Wav/CCF002_Pa002\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Clean/Wav/CCF004_Pa004\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Clean/Wav/CCF005_Pa005\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Clean/Wav/CCF007_Pa007\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Clean/Wav/CCF008_Pa008\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Clean/Wav/CCF009_Pa009\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Clean/Wav/CCF011_Pa011\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Clean/Wav/CCF014_Pa014\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Clean/Wav/CCF017_Pa017\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Clean/Wav/CCF020_Pa020\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Clean/Wav/CCF024_Pa024\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Clean/Wav/CCM025_Pa025\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Clean/Wav/CCM027_Pa027\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Clean/Wav/CCM030_Pa030\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Clean/Wav/CCM032_Pa032\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Clean/Wav/CCM034_Pa034\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Clean/Wav/CCM036_Pa036\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Clean/Wav/CCM037_Pa037\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Clean/Wav/CCM040_Pa040\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Clean/Wav/CCM043_Pa043\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Clean/Wav/CCM044_Pa044\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Clean/Wav/CCM046_Pa046\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Clean/Wav/CCM047_Pa047\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Office/Wav/COF001_Pa001\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Office/Wav/COF002_Pa002\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Office/Wav/COF004_Pa004\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Office/Wav/COF005_Pa005\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Office/Wav/COF007_Pa007\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Office/Wav/COF008_Pa008\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Office/Wav/COF009_Pa009\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Office/Wav/COF011_Pa011\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Office/Wav/COF014_Pa014\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Office/Wav/COF017_Pa017\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Office/Wav/COF020_Pa020\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Office/Wav/COF024_Pa024\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Office/Wav/COM025_Pa025\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Office/Wav/COM027_Pa027\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Office/Wav/COM030_Pa030\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Office/Wav/COM032_Pa032\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Office/Wav/COM034_Pa034\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Office/Wav/COM036_Pa036\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Office/Wav/COM037_Pa037\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Office/Wav/COM040_Pa040\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Office/Wav/COM043_Pa043\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Office/Wav/COM044_Pa044\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Office/Wav/COM046_Pa046\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/C/Office/Wav/COM047_Pa047\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Clean/Wav/UCF001_Pa001\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Clean/Wav/UCF002_Pa002\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Clean/Wav/UCF004_Pa004\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Clean/Wav/UCF005_Pa005\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Clean/Wav/UCF007_Pa007\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Clean/Wav/UCF008_Pa008\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Clean/Wav/UCF009_Pa009\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Clean/Wav/UCF011_Pa011\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Clean/Wav/UCF014_Pa014\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Clean/Wav/UCF017_Pa017\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Clean/Wav/UCF020_Pa020\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Clean/Wav/UCF024_Pa024\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Clean/Wav/UCM025_Pa025\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Clean/Wav/UCM027_Pa027\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Clean/Wav/UCM030_Pa030\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Clean/Wav/UCM032_Pa032\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Clean/Wav/UCM034_Pa034\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Clean/Wav/UCM036_Pa036\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Clean/Wav/UCM037_Pa037\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Clean/Wav/UCM040_Pa040\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Clean/Wav/UCM043_Pa043\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Clean/Wav/UCM044_Pa044\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Clean/Wav/UCM046_Pa046\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Clean/Wav/UCM047_Pa047\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOF001_Pa001\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOF002_Pa002\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOF004_Pa004\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOF005_Pa005\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOF007_Pa007\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOF008_Pa008\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOF009_Pa009\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOF011_Pa011\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOF014_Pa014\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOF017_Pa017\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOF020_Pa020\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOF024_Pa024\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOM025_Pa025\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOM027_Pa027\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOM030_Pa030\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOM032_Pa032\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOM034_Pa034\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOM036_Pa036\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOM037_Pa037\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOM040_Pa040\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOM043_Pa043\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOM044_Pa044\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOM046_Pa046\",\n","    \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOM047_Pa047\",\n","\n","]\n","\n","csv_unificato = \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/merged_dataset2.csv\"\n","df_totale = pd.DataFrame()\n","\n","for cartella in cartelle:\n","    for root, _, files in os.walk(cartella):\n","        for file in files:\n","            if file == \"pronunciation_error_dataset.csv\":\n","                csv_path = os.path.join(root, file)\n","                df = pd.read_csv(csv_path)\n","                df_totale = pd.concat([df_totale, df], ignore_index=True)\n","\n","df_totale.to_csv(csv_unificato, index=False)\n","print(f\"✅ CSV unificato salvato in: {csv_unificato}\")\n"]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1e-iPV0DsWMWH4VyC9IBWzlNABE_cli5O","authorship_tag":"ABX9TyPXJXHUdXHaQpsKLVHKPdYp"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNioqKpfR/NofUN9yZsI42Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"b8eOk_WJj6mb"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install -q torchaudio transformers datasets soundfile\n","!apt-get install -y -qq ffmpeg\n","!pip install gtts\n","!pip install torch torchaudio transformers librosa soundfile\n","!apt-get install -y ffmpeg\n","!pip install sacremoses\n","!pip install pythainlp\n"],"metadata":{"id":"iR8IEIfWkBDs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Creazione del file di creazione del testset Per Tipolofìgia di errori inseriti"],"metadata":{"id":"CIfb6k7Kj_4o"}},{"cell_type":"code","source":["import pandas as pd\n","from datasets import load_from_disk\n","\n","# === CONFIG ===\n","DATASET_DIR = \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/modello_finetunato_th_errori\"\n","CSV_ORIGINALE = \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/merged_dataset.csv\"\n","OUTPUT_CSV = \"/content/drive/MyDrive/TesiMaggistrale/testeset.csv\"\n","\n","# --- Carica dataset preprocessato ---\n","dataset = load_from_disk(DATASET_DIR)\n","test_dataset = dataset[\"test\"]\n","\n","# --- Carica CSV originale ---\n","df_orig = pd.read_csv(CSV_ORIGINALE)\n","\n","# --- Ricrea audio_path per il testset ---\n","# HuggingFace non salva più gli indici originali, quindi selezioniamo il test split usando la stessa logica di train_test_split\n","# Supponiamo che tu abbia usato train_test_split con seed=42 e le stesse percentuali.\n","# Qui prendiamo semplicemente le ultime righe del CSV (come esempio)\n","# (devi adattare in base a come hai splittato)\n","num_test = len(test_dataset)\n","df_test_csv = df_orig.iloc[-num_test:][[\"audio_path\", \"trascrizione_originale\", \"trascrizione_errata\", \"dettagli_modifiche\"]].reset_index(drop=True)\n","\n","# --- Converto test_dataset in DataFrame ---\n","df_test_hf = test_dataset.to_pandas()\n","\n","# --- Allinea le colonne ---\n","df_finale = pd.concat([df_test_hf.reset_index(drop=True), df_test_csv], axis=1)\n","\n","# --- Rinomina ---\n","df_finale = df_finale.rename(columns={\"trascrizione_originale\": \"trascrizione_corretta\"})\n","\n","# --- Mantieni solo le colonne desiderate ---\n","df_finale = df_finale[[\"input_values\", \"labels\", \"trascrizione_corretta\", \"trascrizione_errata\", \"dettagli_modifiche\", \"audio_path\"]]\n","\n","# --- Salva CSV ---\n","df_finale.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8\")\n","print(f\"✅ File di test salvato in: {OUTPUT_CSV}\")\n","print(df_finale.head())\n"],"metadata":{"id":"Jl5_zgEdkHZI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import difflib\n","import unicodedata\n","\n","# --- CONFIG PATH ---\n","INPUT_CSV = \"/content/drive/MyDrive/TesiMaggistrale/testeset.csv\"\n","OUTPUT_CSV = \"/content/drive/MyDrive/TesiMaggistrale/testeset_updated_from_pairs.csv\"\n","\n","# --- MAPPINGS (ricavati dal tuo codice di injection) ---\n","# tonal marks come li avevi:\n","tones = ['่', '้', '๊', '๋']\n","\n","# costruisco i set di vocali e consonanti dalle mappe che mi hai mostrato\n","pronunciation_confusions = {\n","    'light': {\n","        'consonants': {\n","            'ด': ['ต'], 'ต': ['ด'],\n","            'ร': ['ล'], 'ล': ['ร'],\n","            'บ': ['ป'], 'ป': ['บ'],\n","            'น': ['ม'], 'ม': ['น'],\n","        },\n","        'vowels': {\n","            'า': ['ั'], 'ั': ['า'],\n","            'เ': ['แ'], 'แ': ['เ'],\n","            'ะ': ['า'], 'า': ['ะ'],\n","        },\n","    },\n","    'heavy': {\n","        'consonants': {\n","            'บ': ['พ'], 'พ': ['บ'],\n","            'ช': ['ซ'], 'ซ': ['ช'],\n","            'ง': ['น'], 'น': ['ง'],\n","            'ก': ['ข', 'ค'], 'ข': ['ก'], 'ค': ['ก'],\n","            'ญ': ['ย'], 'ย': ['ญ'],\n","        },\n","        'vowels': {\n","            'ิ': ['ี'], 'ี': ['ิ'],\n","            'ุ': ['ู'], 'ู': ['ุ'],\n","            'อ': ['โ'], 'โ': ['อ'],\n","        },\n","    },\n","    'tones': tones\n","}\n","\n","# costruzione set vowel e consonant includendo chiavi e valori\n","vowel_set = set()\n","for mode in ['light', 'heavy']:\n","    vowel_dict = pronunciation_confusions[mode].get('vowels', {})\n","    for k,vlist in vowel_dict.items():\n","        vowel_set.add(k)\n","        for v in vlist:\n","            vowel_set.add(v)\n","# aggiungo vocali thai comuni che possono comparire\n","vowel_set.update(list(\"าเแะิีุูโ็ํ\"))  # espandibile se necessario\n","\n","consonant_set = set()\n","for mode in ['light', 'heavy']:\n","    cons_dict = pronunciation_confusions[mode].get('consonants', {})\n","    for k,vlist in cons_dict.items():\n","        consonant_set.add(k)\n","        for v in vlist:\n","            consonant_set.add(v)\n","# aggiungo consonanti thai comuni (espandibile)\n","consonant_set.update(list(\"กขคฆงจชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลวสหฬฮ\"))\n","\n","tone_set = set(tones)\n","\n","# funzione di utilità: normalizza le stringhe (NFC) per confronti consistenti\n","def normalize_text(s):\n","    if pd.isna(s):\n","        return \"\"\n","    return unicodedata.normalize('NFC', str(s))\n","\n","# funzione che classifica un singolo cambiamento (char o sequence) in T/V/C (o None)\n","def classify_char_change(char):\n","    if char == \"\":\n","        return None\n","    # char potrebbe essere più di un codice (es. segno di tono)\n","    # controlliamo se contiene almeno un carattere di tono\n","    if any(c in tone_set for c in char):\n","        return 'TONO'\n","    # se tutti i caratteri appartengono al vowel_set (o contiene almeno uno), consideriamo VOCALE\n","    if any(c in vowel_set for c in char):\n","        return 'VOCALE'\n","    # se contiene consonanti\n","    if any(c in consonant_set for c in char):\n","        return 'CONSONANTE'\n","    # fallback: None (non classificabile)\n","    return None\n","\n","# funzione principale: prende due stringhe e ritorna set di tipi trovati\n","def classify_changes_between_strings(ref, hyp):\n","    \"\"\"\n","    ref: trascrizione_corretta (stringa)\n","    hyp: trascrizione_errata (stringa)\n","    restituisce: set di tipi tra {'TONO','VOCALE','CONSONANTE'} (vuoto se nessuna)\n","    \"\"\"\n","    ref = normalize_text(ref)\n","    hyp = normalize_text(hyp)\n","    sm = difflib.SequenceMatcher(a=ref, b=hyp, autojunk=False)\n","    types_found = set()\n","\n","    for tag, i1, i2, j1, j2 in sm.get_opcodes():\n","        # tag in {'replace', 'delete', 'insert', 'equal'}\n","        if tag == 'equal':\n","            continue\n","        # segmenti coinvolti\n","        removed = ref[i1:i2]   # parte rimossa o sostituita\n","        inserted = hyp[j1:j2]  # parte inserita o sostituita\n","\n","        # classify removed (deletion or from substitution)\n","        t_removed = classify_char_change(removed)\n","        t_inserted = classify_char_change(inserted)\n","\n","        if t_removed:\n","            types_found.add(t_removed)\n","        if t_inserted:\n","            types_found.add(t_inserted)\n","\n","        # corner case: substitution where removed empty and inserted empty handled\n","        # also handle case where removed/inserted are multiple char sequences:\n","        # try to analyze per-char if whole span not classified\n","        if not t_removed and removed:\n","            for ch in removed:\n","                tch = classify_char_change(ch)\n","                if tch:\n","                    types_found.add(tch)\n","        if not t_inserted and inserted:\n","            for ch in inserted:\n","                tch = classify_char_change(ch)\n","                if tch:\n","                    types_found.add(tch)\n","\n","    return types_found\n","\n","# --- Caricamento CSV e applicazione ---\n","df = pd.read_csv(INPUT_CSV, dtype=str)  # carichiamo come stringhe per sicurezza\n","\n","# Assicuriamoci che le colonne esistano\n","required_cols = ['trascrizione_corretta', 'trascrizione_errata']\n","for c in required_cols:\n","    if c not in df.columns:\n","        raise ValueError(f\"Colonna mancante nel CSV: {c}\")\n","\n","new_types = []\n","for idx, row in df.iterrows():\n","    ref = row['trascrizione_corretta']\n","    hyp = row['trascrizione_errata']\n","    types = classify_changes_between_strings(ref, hyp)\n","    if len(types) == 0:\n","        new_types.append('NESSUNA')\n","    else:\n","        # ordino per consistenza e concateno con ;\n","        new_types.append(';'.join(sorted(types)))\n","\n","df['dettagli_modifiche'] = new_types\n","\n","# Salvo il CSV aggiornato\n","df.to_csv(OUTPUT_CSV, index=False, encoding='utf-8')\n","print(\"Salvato:\", OUTPUT_CSV)\n","print(df[['trascrizione_corretta','trascrizione_errata','dettagli_modifiche']].head(12))\n"],"metadata":{"id":"5ARjG7STkJCV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" import pandas as pd\n","import difflib\n","import unicodedata\n","\n","# --- CONFIG ---\n","INPUT_CSV = \"/content/drive/MyDrive/TesiMaggistrale/testeset.csv\"\n","OUTPUT_CSV = \"/content/drive/MyDrive/TesiMaggistrale/testeset_with_counts.csv\"\n","\n","# --- Set completi Thai ---\n","thai_vowels = set('ะัาำิีึืฺุูเแโใไฤฦๅ')  # Vowel signs\n","thai_consonants = set('กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผพฟภมยรฤลฦวศษสหฬอฮ')\n","thai_tones = set('่้๊๋')  # Tone marks\n","\n","# --- Funzioni di supporto ---\n","def classify_char(char):\n","    if char in thai_tones:\n","        return 'TONO'\n","    elif char in thai_vowels:\n","        return 'VOCALE'\n","    elif char in thai_consonants:\n","        return 'CONSONANTE'\n","    return None\n","\n","def normalize_text(s):\n","    if pd.isna(s):\n","        return \"\"\n","    return unicodedata.normalize('NFC', str(s)).replace(\" \", \"\")\n","\n","def count_changes_between_strings(ref, hyp):\n","    ref = normalize_text(ref)\n","    hyp = normalize_text(hyp)\n","    sm = difflib.SequenceMatcher(a=ref, b=hyp, autojunk=False)\n","    counts = {'TONO': 0, 'VOCALE': 0, 'CONSONANTE': 0}\n","\n","    for tag, i1, i2, j1, j2 in sm.get_opcodes():\n","        removed = ref[i1:i2]\n","        inserted = hyp[j1:j2]\n","\n","        if tag == 'equal':\n","            continue\n","        elif tag == 'replace':\n","            # Conta tutti i caratteri sostituiti una sola volta\n","            # allineando quelli corrispondenti\n","            for r, c in zip(removed, inserted):\n","                t_c = classify_char(c)\n","                if t_c: counts[t_c] += 1\n","            # Se ci sono caratteri extra in removed o inserted, contali\n","            for r in removed[len(inserted):]:\n","                t_r = classify_char(r)\n","                if t_r: counts[t_r] += 1\n","            for c in inserted[len(removed):]:\n","                t_c = classify_char(c)\n","                if t_c: counts[t_c] += 1\n","        else:  # 'insert' o 'delete'\n","            for r in removed:\n","                t_r = classify_char(r)\n","                if t_r: counts[t_r] += 1\n","            for c in inserted:\n","                t_c = classify_char(c)\n","                if t_c: counts[t_c] += 1\n","\n","    return counts\n","\n","# --- Carica CSV ---\n","df = pd.read_csv(INPUT_CSV, dtype=str)\n","\n","# --- Controllo colonne necessarie ---\n","required_cols = ['trascrizione_corretta', 'trascrizione_errata']\n","for c in required_cols:\n","    if c not in df.columns:\n","        raise ValueError(f\"Colonna mancante: {c}\")\n","\n","# --- Calcolo tipi concatenati e conteggi ---\n","concat_types = []\n","tono_counts = []\n","vocale_counts = []\n","consonante_counts = []\n","\n","for idx, row in df.iterrows():\n","    counts = count_changes_between_strings(row['trascrizione_corretta'], row['trascrizione_errata'])\n","    tipo_riga = [k for k, v in counts.items() if v > 0]\n","    concat_types.append(';'.join(tipo_riga) if tipo_riga else 'NESSUNA')\n","    tono_counts.append(counts['TONO'])\n","    vocale_counts.append(counts['VOCALE'])\n","    consonante_counts.append(counts['CONSONANTE'])\n","\n","df['dettagli_modifiche'] = concat_types\n","df['TONO_count'] = tono_counts\n","df['VOCALE_count'] = vocale_counts\n","df['CONSONANTE_count'] = consonante_counts\n","\n","# --- Salva CSV aggiornato ---\n","df.to_csv(OUTPUT_CSV, index=False, encoding='utf-8')\n","print(\"✅ Salvato:\", OUTPUT_CSV)\n"],"metadata":{"id":"Gb4GpNFgkK2l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# --- CONFIG ---\n","INPUT_CSV = \"/content/drive/MyDrive/TesiMaggistrale/testeset_with_counts.csv\"\n","OUTPUT_DIR = \"/content/drive/MyDrive/TesiMaggistrale/TestSuTipologia/\"\n","\n","# --- Carica CSV aggiornato ---\n","df = pd.read_csv(INPUT_CSV, dtype=str)\n","\n","# --- Filtra per singolo tipo di errore ---\n","def filter_single_type(df, tipo):\n","    \"\"\"\n","    Ritorna solo le righe dove dettagli_modifiche contiene il tipo specificato\n","    e non contiene altri tipi.\n","    \"\"\"\n","    return df[df['dettagli_modifiche'] == tipo]\n","\n","# TONO singolo\n","df_tono = filter_single_type(df, 'TONO').head(10)\n","df_tono.to_csv(f\"{OUTPUT_DIR}testset_tono.csv\", index=False, encoding='utf-8')\n","\n","# VOCALE singolo\n","df_vocale = filter_single_type(df, 'VOCALE').head(10)\n","df_vocale.to_csv(f\"{OUTPUT_DIR}testset_vocale.csv\", index=False, encoding='utf-8')\n","\n","# CONSONANTE singolo\n","df_consonante = filter_single_type(df, 'CONSONANTE').head(10)\n","df_consonante.to_csv(f\"{OUTPUT_DIR}testset_consonante.csv\", index=False, encoding='utf-8')\n","\n","print(\"✅ Generati testset separati per TONO, VOCALE e CONSONANTE.\")\n","print(f\"- {len(df_tono)} frasi TONO\")\n","print(f\"- {len(df_vocale)} frasi VOCALE\")\n","print(f\"- {len(df_consonante)} frasi CONSONANTE\")\n"],"metadata":{"id":"NTh-vP5PkMoi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Creazione testset per gli espermenti sulla **quantità di errori** introdotto"],"metadata":{"id":"Vv64KcAFqa0z"}},{"cell_type":"code","source":["import pandas as pd\n","import difflib\n","import unicodedata\n","\n","# --- CONFIG ---\n","INPUT_CSV = \"/content/drive/MyDrive/TesiMaggistrale/testeset.csv\"\n","OUTPUT_CSV = \"/content/drive/MyDrive/TesiMaggistrale/testeset_with_counts.csv\"\n","\n","# --- Set completi Thai ---\n","thai_vowels = set('ะัาำิีึืฺุูเแโใไฤฦๅ')  # Vowel signs\n","thai_consonants = set('กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผพฟภมยรฤลฦวศษสหฬอฮ')\n","thai_tones = set('่้๊๋')  # Tone marks\n","\n","# --- Funzioni di supporto ---\n","def classify_char(char):\n","    if char in thai_tones:\n","        return 'TONO'\n","    elif char in thai_vowels:\n","        return 'VOCALE'\n","    elif char in thai_consonants:\n","        return 'CONSONANTE'\n","    return None\n","\n","def normalize_text(s):\n","    if pd.isna(s):\n","        return \"\"\n","    return unicodedata.normalize('NFC', str(s)).replace(\" \", \"\")\n","\n","def count_changes_between_strings(ref, hyp):\n","    ref = normalize_text(ref)\n","    hyp = normalize_text(hyp)\n","    sm = difflib.SequenceMatcher(a=ref, b=hyp, autojunk=False)\n","    counts = {'TONO': 0, 'VOCALE': 0, 'CONSONANTE': 0}\n","\n","    for tag, i1, i2, j1, j2 in sm.get_opcodes():\n","        removed = ref[i1:i2]\n","        inserted = hyp[j1:j2]\n","\n","        if tag == 'equal':\n","            continue\n","        elif tag == 'replace':\n","            for r, c in zip(removed, inserted):\n","                t_c = classify_char(c)\n","                if t_c: counts[t_c] += 1\n","            for r in removed[len(inserted):]:\n","                t_r = classify_char(r)\n","                if t_r: counts[t_r] += 1\n","            for c in inserted[len(removed):]:\n","                t_c = classify_char(c)\n","                if t_c: counts[t_c] += 1\n","        else:  # 'insert' o 'delete'\n","            for r in removed:\n","                t_r = classify_char(r)\n","                if t_r: counts[t_r] += 1\n","            for c in inserted:\n","                t_c = classify_char(c)\n","                if t_c: counts[t_c] += 1\n","\n","    return counts\n","\n","# --- Carica CSV ---\n","df = pd.read_csv(INPUT_CSV, dtype=str)\n","\n","# --- Controllo colonne necessarie ---\n","required_cols = ['trascrizione_corretta', 'trascrizione_errata']\n","for c in required_cols:\n","    if c not in df.columns:\n","        raise ValueError(f\"Colonna mancante: {c}\")\n","\n","# --- Calcolo tipi concatenati e conteggi ---\n","concat_types = []\n","tono_counts = []\n","vocale_counts = []\n","consonante_counts = []\n","\n","for idx, row in df.iterrows():\n","    counts = count_changes_between_strings(row['trascrizione_corretta'], row['trascrizione_errata'])\n","    tipo_riga = [k for k, v in counts.items() if v > 0]\n","    concat_types.append(';'.join(tipo_riga) if tipo_riga else 'NESSUNA')\n","    tono_counts.append(counts['TONO'])\n","    vocale_counts.append(counts['VOCALE'])\n","    consonante_counts.append(counts['CONSONANTE'])\n","\n","df['dettagli_modifiche'] = concat_types\n","df['TONO_count'] = tono_counts\n","df['VOCALE_count'] = vocale_counts\n","df['CONSONANTE_count'] = consonante_counts\n","\n","# --- Aggiungi colonna totale errori ---\n","df['TOTALE_errori'] = df['TONO_count'] + df['VOCALE_count'] + df['CONSONANTE_count']\n","\n","# --- Salva CSV aggiornato ---\n","df.to_csv(OUTPUT_CSV, index=False, encoding='utf-8')\n","print(\"✅ Salvato con colonna TOTALE_errori:\", OUTPUT_CSV)\n"],"metadata":{"id":"x-6t_dCXkSw1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# --- CONFIG ---\n","INPUT_CSV = \"/content/drive/MyDrive/TesiMaggistrale/testeset_with_counts.csv\"\n","OUTPUT_DIR = \"/content/drive/MyDrive/TesiMaggistrale/TestSuTotaleErrori/\"\n","\n","# --- Carica CSV aggiornato ---\n","df = pd.read_csv(INPUT_CSV, dtype=str)\n","\n","# Converti TOTALE_errori in intero per poter filtrare numericamente\n","df['TOTALE_errori'] = df['TOTALE_errori'].astype(int)\n","\n","# --- Funzione per selezionare le prime 10 righe con un certo numero di errori ---\n","def select_n_rows_by_total_errors(df, total_errors, n=10):\n","    filtered = df[df['TOTALE_errori'] == total_errors].head(n)\n","    return filtered\n","\n","# --- Genera file CSV per 1,2,3,4,5 errori totali ---\n","for i in range(1, 6):\n","    df_subset = select_n_rows_by_total_errors(df, i, n=10)\n","    df_subset.to_csv(f\"{OUTPUT_DIR}testset_{i}_errori.csv\", index=False, encoding='utf-8')\n","    print(f\"✅ {len(df_subset)} righe con {i} errore totale salvate in testset_{i}_errori.csv\")\n"],"metadata":{"id":"U1hb9UJFkYYa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Genera testset per 8,9 e 10 errori\n"],"metadata":{"id":"bkqJIvQY6vvb"}},{"cell_type":"code","source":["import random\n","import nltk\n","from pythainlp.corpus.common import thai_words\n","from pythainlp.corpus.wordnet import synsets\n","\n","# Assicura la presenza di WordNet\n","try:\n","    nltk.data.find('corpora/omw-1.4')\n","except LookupError:\n","    nltk.download('omw-1.4')\n","\n","# Dizionario confusione esteso\n","pronunciation_confusions = {\n","    'light': {\n","        'consonants': {\n","            'ด': ['ต'], 'ต': ['ด'],\n","            'ร': ['ล'], 'ล': ['ร'],\n","            'บ': ['ป'], 'ป': ['บ'],\n","            'น': ['ม'], 'ม': ['น'],\n","        },\n","        'vowels': {\n","            'า': ['ั'], 'ั': ['า'],\n","            'เ': ['แ'], 'แ': ['เ'],\n","            'ะ': ['า'], 'า': ['ะ'],\n","        },\n","    },\n","    'heavy': {\n","        'consonants': {\n","            'บ': ['พ'], 'พ': ['บ'],\n","            'ช': ['ซ'], 'ซ': ['ช'],\n","            'ง': ['น'], 'น': ['ง'],\n","            'ก': ['ข', 'ค'], 'ข': ['ก'], 'ค': ['ก'],\n","            'ญ': ['ย'], 'ย': ['ญ'],\n","        },\n","        'vowels': {\n","            'ิ': ['ี'], 'ี': ['ิ'],\n","            'ุ': ['ู'], 'ู': ['ุ'],\n","            'อ': ['โ'], 'โ': ['อ'],\n","        },\n","    },\n","    'tones': ['่', '้', '๊', '๋']\n","}\n","\n","# combinazioni per fallback forzato\n","combined_consonants = {}\n","combined_vowels = {}\n","for lvl in ['light', 'heavy']:\n","    for k, v in pronunciation_confusions[lvl]['consonants'].items():\n","        combined_consonants.setdefault(k, set()).update(v)\n","    for k, v in pronunciation_confusions[lvl]['vowels'].items():\n","        combined_vowels.setdefault(k, set()).update(v)\n","combined_consonants = {k: list(v) for k, v in combined_consonants.items()}\n","combined_vowels = {k: list(v) for k, v in combined_vowels.items()}\n","\n","thai_vocab = set(thai_words())\n","tone_possible_chars = set(\"กขคฆงจชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลวสหฬอฮ\")\n","\n","\n","def is_valid_lexical(word):\n","    return word in thai_vocab\n","\n","\n","def is_valid_semantic(word):\n","    return len(synsets(word)) > 0\n","\n","\n","def generate_pronunciation_variants(word, severity='light', max_steps=3):\n","    consonants = pronunciation_confusions.get(severity, {}).get('consonants', {})\n","    vowels = pronunciation_confusions.get(severity, {}).get('vowels', {})\n","    tones = pronunciation_confusions['tones']\n","\n","    variants = set()\n","\n","    def recursive_modify(current_word, steps_left, changes):\n","        if steps_left == 0:\n","            return\n","\n","        for i, char in enumerate(current_word):\n","            new_variants = []\n","\n","            # Sostituzione consonante\n","            if char in consonants:\n","                for rep in consonants[char]:\n","                    mod_word = current_word[:i] + rep + current_word[i+1:]\n","                    new_variants.append((mod_word, changes + [(char, rep, 'suono_consonante')]))\n","\n","            # Sostituzione vocale\n","            if char in vowels:\n","                for rep in vowels[char]:\n","                    mod_word = current_word[:i] + rep + current_word[i+1:]\n","                    new_variants.append((mod_word, changes + [(char, rep, 'suono_vocale')]))\n","\n","            # Inserimento di tono (dopo il carattere)\n","            if char in tone_possible_chars:\n","                for tone in tones:\n","                    mod_word = current_word[:i+1] + tone + current_word[i+1:]\n","                    new_variants.append((mod_word, changes + [('', tone, 'aggiunta_tono')]))\n","\n","            # Rimozione/sostituzione di vocale/tono\n","            if char in list(vowels.keys()):\n","                alt_chars = [v for v in vowels[char] if v != char]\n","                for alt in alt_chars:\n","                    mod_word = current_word[:i] + alt + current_word[i+1:]\n","                    new_variants.append((mod_word, changes + [(char, alt, 'sostituzione_vocale')]))\n","            if char in tones:\n","                alt_chars = [t for t in tones if t != char]\n","                for alt in alt_chars:\n","                    mod_word = current_word[:i] + alt + current_word[i+1:]\n","                    new_variants.append((mod_word, changes + [(char, alt, 'sostituzione_tono')]))\n","\n","            for variant, var_changes in new_variants:\n","                if (variant, tuple(var_changes)) not in variants:\n","                    variants.add((variant, tuple(var_changes)))\n","                    recursive_modify(variant, steps_left - 1, var_changes)\n","\n","    recursive_modify(word, max_steps, [])\n","    return list(variants)\n","\n","\n","def force_modify_word(word):\n","    if not word:\n","        return word, []\n","\n","    i = random.randrange(len(word))\n","    char = word[i]\n","\n","    if char in combined_consonants and random.random() < 0.6:\n","        rep = random.choice(combined_consonants[char])\n","        new_word = word[:i] + rep + word[i+1:]\n","        return new_word, [(char, rep, 'forzata_sostituzione_consonante')]\n","\n","    if char in combined_vowels and random.random() < 0.6:\n","        rep = random.choice(combined_vowels[char])\n","        new_word = word[:i] + rep + word[i+1:]\n","        return new_word, [(char, rep, 'forzata_sostituzione_vocale')]\n","\n","    if char in tone_possible_chars:\n","        tone = random.choice(pronunciation_confusions['tones'])\n","        new_word = word[:i+1] + tone + word[i+1:]\n","        return new_word, [('', tone, 'forzata_aggiunta_tono')]\n","\n","    all_replacements = []\n","    for lst in combined_consonants.values():\n","        all_replacements.extend(lst)\n","    for lst in combined_vowels.values():\n","        all_replacements.extend(lst)\n","    if all_replacements:\n","        rep = random.choice(all_replacements)\n","        new_word = word[:i] + rep + word[i+1:]\n","        return new_word, [(char, rep, 'forzata_sostituzione_generica')]\n","\n","    return word, []\n","\n","\n","def inject_pronunciation_error(word, severity='light', max_steps=3, require_valid=True, allow_force=False):\n","    variants = generate_pronunciation_variants(word, severity=severity, max_steps=max_steps)\n","\n","    if require_valid:\n","        valid_variants = [(w, list(changes)) for (w, changes) in variants\n","                          if (is_valid_lexical(w) or is_valid_semantic(w)) and w != word]\n","    else:\n","        valid_variants = [(w, list(changes)) for (w, changes) in variants if w != word]\n","\n","    if valid_variants:\n","        chosen_word, changes = random.choice(valid_variants)\n","        return chosen_word, changes, True\n","\n","    if allow_force:\n","        forced_word, forced_changes = force_modify_word(word)\n","        if forced_word != word and forced_changes:\n","            return forced_word, forced_changes, True\n","\n","    return word, [], False\n","\n","\n","def inject_exact_num_errors(sentence, reference_sentence, target_errors=8,\n","                            severity='light', require_valid=True, allow_force=True, max_per_word=None):\n","    words = sentence.split()\n","    new_words = words[:]\n","    reference_words = reference_sentence.split()\n","\n","    errors_injected = 0\n","    change_log = []\n","    per_word_count = [0] * len(new_words)\n","\n","    stages = [\n","        {'require_valid': require_valid, 'allow_force': False},\n","        {'require_valid': False, 'allow_force': False},\n","        {'require_valid': False, 'allow_force': allow_force},\n","    ]\n","\n","    for stage in stages:\n","        req = stage['require_valid']\n","        af = stage['allow_force']\n","\n","        if errors_injected >= target_errors:\n","            break\n","\n","        no_progress_rounds = 0\n","        while errors_injected < target_errors and no_progress_rounds < 3:\n","            indices = list(range(len(new_words)))\n","            random.shuffle(indices)\n","            progress_this_round = False\n","\n","            for i in indices:\n","                if errors_injected >= target_errors:\n","                    break\n","\n","                if max_per_word is not None and per_word_count[i] >= max_per_word:\n","                    continue\n","\n","                original_word = new_words[i]\n","                chosen_word, changes, applied = inject_pronunciation_error(\n","                    original_word, severity=severity, max_steps=1, require_valid=req, allow_force=af\n","                )\n","\n","                if applied and chosen_word != original_word and len(changes) > 0:\n","                    change_log.append((i, original_word, chosen_word, changes))\n","                    new_words[i] = chosen_word\n","                    per_word_count[i] += len(changes)\n","                    errors_injected += len(changes)\n","                    progress_this_round = True\n","\n","                    if errors_injected >= target_errors:\n","                        break\n","\n","            if not progress_this_round:\n","                no_progress_rounds += 1\n","            else:\n","                no_progress_rounds = 0\n","\n","    if errors_injected > target_errors:\n","        while errors_injected > target_errors and change_log:\n","            idx, orig, neww, changes = change_log.pop()\n","            new_words[idx] = orig\n","            errors_injected -= len(changes)\n","\n","    success = (errors_injected == target_errors)\n","    final_sentence = ' '.join(new_words[:len(reference_words)])\n","\n","    full_changes = []\n","    for idx, orig, new_w, changes in change_log:\n","        full_changes.append({\n","            'index': idx,\n","            'original': orig,\n","            'modified': new_w,\n","            'changes': changes\n","        })\n","\n","    return final_sentence, full_changes, errors_injected, success\n","\n","\n","if __name__ == \"__main__\":\n","    original_sentence = \"ฉัน รัก ภาษาไทย มาก มาก จริง ๆ วันนี้ สนุก\"\n","    reference_sentence = original_sentence\n","\n","    # scegli a caso 8, 9 o 10\n","    target = random.choice([8, 9, 10])\n","\n","    corrupted, error_log, injected_count, success = inject_exact_num_errors(\n","        original_sentence,\n","        reference_sentence,\n","        target_errors=target,\n","        severity='light',\n","        require_valid=True,\n","        allow_force=True,\n","        max_per_word=1   # così una parola non viene modificata troppe volte\n","    )\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(f\"Target scelto casualmente: {target}\")\n","    print(\"Originale: \", original_sentence)\n","    print(\"Corrotto:  \", corrupted)\n","    print(f\"Errori iniettati: {injected_count}  Successo esatto?: {success}\")\n","    print(\"--- Log dettagliato ---\")\n","    if not error_log:\n","        print(\"Nessuna modifica effettuata.\")\n","    else:\n","        for idx, entry in enumerate(error_log, 1):\n","            i = entry['index']\n","            print(f\"{idx}. index parola={i} '{entry['original']}' -> '{entry['modified']}'\")\n","            for old, new_c, err_type in entry['changes']:\n","                if old == '':\n","                    print(f\"    + Aggiunto tono: '{new_c}' ({err_type})\")\n","                elif new_c == '':\n","                    print(f\"    - Rimosso '{old}' ({err_type})\")\n","                else:\n","                    print(f\"    x {err_type.upper()} - '{old}' → '{new_c}'\")\n"],"metadata":{"id":"jUsgEJDckcb3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import csv\n","import random\n","import torchaudio\n","import torchaudio.transforms as T\n","from transformers import pipeline\n","from pythaitts import TTS\n","\n","# Percorsi\n","AUDIO_DIR = \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/U/Office/Wav/UOM046_Pa046\"\n","OUTPUT_DIR = \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/Corpus_Injection_error_thai/\"\n","CSV_PATH = os.path.join(OUTPUT_DIR, \"testseterrori.csv\")\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","# Modelli\n","sr_pipe = pipeline(\"automatic-speech-recognition\", model=\"airesearch/wav2vec2-large-xlsr-53-th\")\n","tts_model = TTS(pretrained=\"khanomtan\", version=\"1.0\", mode=\"best_model\")\n","\n","# Funzione per preparare audio per ASR\n","def prepara_audio(path):\n","    waveform, sr = torchaudio.load(path)\n","    if waveform.shape[0] > 1:\n","        waveform = waveform.mean(dim=0, keepdim=True)\n","    if sr != 16000:\n","        waveform = T.Resample(sr, 16000)(waveform)\n","    return waveform.squeeze().numpy()\n","\n","# Inizializza il CSV con intestazioni se non esiste\n","if not os.path.exists(CSV_PATH):\n","    with open(CSV_PATH, mode=\"w\", encoding=\"utf-8\", newline=\"\") as f:\n","        writer = csv.writer(f)\n","        writer.writerow([\n","            \"filename\",\n","            \"trascrizione_originale\",\n","            \"trascrizione_errata\",\n","            \"Totale_errori\",\n","            \"modificata\",\n","            \"dettagli_modifiche\",\n","            \"audio_path\"\n","        ])\n","\n","# Trova file audio\n","audio_files = []\n","for root, _, files in os.walk(AUDIO_DIR):\n","    for file in files:\n","        if file.endswith(\".wav\"):\n","            audio_files.append(os.path.join(root, file))\n","\n","print(f\"Trovati {len(audio_files)} file audio.\")\n","\n","# Loop sui file audio\n","for audio_path in audio_files:\n","    try:\n","        base_name = os.path.splitext(os.path.basename(audio_path))[0]\n","\n","        # Step 1: ASR\n","        audio_data = prepara_audio(audio_path)\n","        trascrizione = sr_pipe(audio_data)[\"text\"].strip()\n","        reference_sentence = trascrizione\n","\n","        # Step 2: Iniezione errori (assicura 8, 9 o 10)\n","        target_errors = random.choice([8, 9, 10])\n","        max_attempts = 10  # evita loop infinito\n","        attempt = 0\n","        success = False\n","\n","        while attempt < max_attempts and not success:\n","            frase_errata, log_error, injected_count, success_flag = inject_exact_num_errors(\n","                trascrizione,\n","                reference_sentence,\n","                target_errors=target_errors,\n","                severity='light',\n","                require_valid=True,\n","                allow_force=True,\n","                max_per_word=1\n","            )\n","            if injected_count == target_errors and success_flag:\n","                success = True\n","            else:\n","                attempt += 1\n","\n","        if not success:\n","            print(f\"⚠️ Attenzione: impossibile iniettare esattamente {target_errors} errori in {base_name}. Si procede comunque.\")\n","\n","        # Step 3: TTS\n","        audio_out_path = os.path.join(OUTPUT_DIR, f\"{base_name}_corrupted.wav\")\n","        tts_model.tts(\n","            text=frase_errata,\n","            speaker_idx=\"Tsyncone\",\n","            language_idx=\"th-th\",\n","            return_type=\"file\",\n","            filename=audio_out_path\n","        )\n","\n","        # Step 4: Log dettagliato modifiche\n","        if not log_error:\n","            dettagli = \"Nessuna modifica\"\n","        else:\n","            dettaglio_lista = []\n","            for entry in log_error:\n","                original = entry['original']\n","                modified = entry['modified']\n","                for old, new_c, tipo in entry['changes']:\n","                    if old == '':\n","                        dettaglio_lista.append(f\"Aggiunto tono '{new_c}' in '{modified}'\")\n","                    elif new_c == '':\n","                        dettaglio_lista.append(f\"Rimosso '{old}' da '{original}'\")\n","                    else:\n","                        dettaglio_lista.append(f\"{tipo.upper()} - '{original}': '{old}'→'{new_c}'\")\n","            dettagli = \" | \".join(dettaglio_lista)\n","\n","        # Step 5: Salva nel CSV (7 colonne, ordine coerente)\n","        with open(CSV_PATH, mode=\"a\", encoding=\"utf-8\", newline=\"\") as f:\n","            writer = csv.writer(f)\n","            writer.writerow([\n","                base_name,\n","                trascrizione,\n","                frase_errata,\n","                injected_count,             # Totale_errori PRIMA\n","                \"SI\" if success else \"NO\",  # modificata\n","                dettagli,\n","                audio_out_path\n","            ])\n","\n","        print(f\"✅ Salvato: {base_name} (target errori={target_errors}, effettivi={injected_count})\")\n","\n","    except Exception as e:\n","        print(f\"❌ Errore su {audio_path}: {str(e)}\")\n","\n","print(\"✅ Creazione database completata.\")\n"],"metadata":{"id":"l4W2CdJrke_m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","import torchaudio\n","from transformers import AutoProcessor\n","\n","# === CONFIG ===\n","CSV_PATH = \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/Corpus_Injection_error_thai/testseterrori.csv\"\n","OUTPUT_CSV = \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/Corpus_Injection_error_thai/testseterrori_preprocessed.csv\"\n","SAMPLING_RATE = 16000\n","PRETRAINED_MODEL_NAME = \"airesearch/wav2vec2-large-xlsr-53-th\"\n","\n","# === STEP 1: Carica CSV (tutte le colonne) ===\n","df = pd.read_csv(CSV_PATH)\n","\n","# Teniamo solo le righe con trascrizione_errata valida e file audio esistenti\n","df = df.dropna(subset=[\"trascrizione_errata\"])\n","df = df[df[\"audio_path\"].apply(os.path.exists)].reset_index(drop=True)\n","\n","# === STEP 2: Carica processor ===\n","processor = AutoProcessor.from_pretrained(PRETRAINED_MODEL_NAME)\n","\n","# === STEP 3: Funzione per estrarre input_values e labels ===\n","def extract_features(row):\n","    try:\n","        waveform, sr = torchaudio.load(row[\"audio_path\"])\n","\n","        # Resample se necessario\n","        if sr != SAMPLING_RATE:\n","            resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=SAMPLING_RATE)\n","            waveform = resampler(waveform)\n","\n","        # Input values per il modello\n","        input_values = processor(\n","            waveform.squeeze().numpy(),\n","            sampling_rate=SAMPLING_RATE\n","        ).input_values[0]\n","\n","        # Labels (trascrizione tokenizzata)\n","        with processor.as_target_processor():\n","            labels = processor(row[\"trascrizione_errata\"]).input_ids\n","\n","        return pd.Series({\n","            \"input_values\": input_values,\n","            \"labels\": labels\n","        })\n","\n","    except Exception as e:\n","        print(f\"Errore su file {row['audio_path']}: {e}\")\n","        return pd.Series({\"input_values\": None, \"labels\": None})\n","\n","# === STEP 4: Applica la funzione al DataFrame ===\n","features = df.apply(extract_features, axis=1)\n","df = pd.concat([features, df], axis=1)  # input_values e labels in testa\n","\n","# === STEP 5: Riordina le colonne ===\n","ordered_cols = [\n","    \"input_values\",\n","    \"labels\",\n","    \"trascrizione_originale\",\n","    \"trascrizione_errata\",\n","    \"dettagli_modifiche\",\n","    \"audio_path\",\n","    \"Totale_errori\"\n","]\n","df = df[ordered_cols]\n","\n","# === STEP 6: Salva il nuovo CSV ===\n","df.to_csv(OUTPUT_CSV, index=False)\n","\n","print(\"CSV preprocessato salvato in:\", OUTPUT_CSV)\n","print(\"Righe valide:\", len(df))\n"],"metadata":{"id":"3R5mlqtTkh9z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# --- CONFIG ---\n","INPUT_CSV = \"/content/drive/MyDrive/TesiMaggistrale/audiErrati/Corpus_Injection_error_thai/testseterrori.csv\"\n","OUTPUT_DIR = \"/content/drive/MyDrive/TesiMaggistrale/TestSuTotaleErrori/\"\n","\n","# --- Carica CSV ---\n","df = pd.read_csv(INPUT_CSV, dtype=str)\n","\n","# --- Normalizza il nome della colonna ---\n","if \"Totale_errori\" in df.columns:\n","    df.rename(columns={\"Totale_errori\": \"TOTALE_errori\"}, inplace=True)\n","\n","# Converti in int per filtrare numericamente\n","df[\"TOTALE_errori\"] = df[\"TOTALE_errori\"].astype(int)\n","\n","# --- Funzione per selezionare le prime n righe con un certo numero di errori ---\n","def select_n_rows_by_total_errors(df, total_errors, n=10):\n","    return df[df[\"TOTALE_errori\"] == total_errors].head(n)\n","\n","# --- Genera file CSV per un certo intervallo di errori ---\n","for i in range(8, 11):  # 8, 9, 10 errori\n","    df_subset = select_n_rows_by_total_errors(df, i, n=10)\n","    df_subset.to_csv(f\"{OUTPUT_DIR}testset_{i}_errori.csv\", index=False, encoding=\"utf-8\")\n","    print(f\"✅ {len(df_subset)} righe con {i} errori totali salvate in testset_{i}_errori.csv\")\n"],"metadata":{"id":"yrCOm-Oqkj1j"},"execution_count":null,"outputs":[]}]}